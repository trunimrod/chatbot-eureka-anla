{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Chatbot Eureka con Base de Datos Externa\n",
    "\n",
    "**Objetivo:** Cargar la base de datos vectorial pre-existente desde la carpeta `eureka_chroma_db` y ejecutar la aplicaci√≥n del chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 1: Crear el Archivo de la Aplicaci√≥n Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app_chatbot.py\n",
    "import streamlit as st\n",
    "import time\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Dependencias de LangChain\n",
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- L√≥gica del Chatbot Eureka ---\n",
    "\n",
    "@dataclass\n",
    "class EurekaConfig:\n",
    "    embedding_model: str = \"mxbai-embed-large\"\n",
    "    llm_model: str = \"llama3.2\"\n",
    "    persist_directory: str = \"./eureka_chroma_db\" # Debe coincidir con el notebook 1\n",
    "    retriever_k: int = 5\n",
    "    temperature: float = 0.1\n",
    "\n",
    "class EurekaChatbot:\n",
    "    def __init__(self, config: EurekaConfig):\n",
    "        self.config = config\n",
    "        self.retriever = None\n",
    "        self.llm = ChatOllama(model=config.llm_model, temperature=config.temperature)\n",
    "        self.prompt_template = self._create_prompt_template()\n",
    "\n",
    "    def _create_prompt_template(self) -> PromptTemplate:\n",
    "        template = \"\"\"# 1. Identidad y Persona Central (Core Persona)... [El mismo prompt detallado de la versi√≥n anterior] ...RESPUESTA DE EUREKA:\"\"\"\n",
    "        return PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "    def initialize_from_disk(self):\n",
    "        logger.info(f\"Cargando base de datos desde '{self.config.persist_directory}'...\")\n",
    "        if not Path(self.config.persist_directory).exists():\n",
    "            logger.error(\"¬°La base de datos no existe!\")\n",
    "            raise FileNotFoundError(f\"El directorio '{self.config.persist_directory}' no fue encontrado. Por favor, ejecuta primero el notebook 'create_database.ipynb'.\")\n",
    "        \n",
    "        embeddings = OllamaEmbeddings(model=self.config.embedding_model)\n",
    "        vectorstore = Chroma(persist_directory=self.config.persist_directory, embedding_function=embeddings)\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": self.config.retriever_k})\n",
    "        logger.info(\"‚úÖ Base de datos cargada y retriever listo.\")\n",
    "\n",
    "    def query(self, question: str) -> Dict:\n",
    "        # ... [El mismo m√©todo query() de la versi√≥n anterior que maneja 'admin:' y extrae m√©tricas] ...\n",
    "        if not self.retriever: raise ValueError(\"Retriever no inicializado.\")\n",
    "        if question.strip().startswith(\"admin:\"): # ...\n",
    "        try:\n",
    "            retrieved_docs = self.retriever.get_relevant_documents(question)\n",
    "            context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "            prompt_formatted = self.prompt_template.format(context=context, question=question)\n",
    "            response_obj = self.llm.invoke(prompt_formatted)\n",
    "            answer = response_obj.content\n",
    "            metadata = response_obj.response_metadata\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"sources\": [doc.metadata for doc in retrieved_docs],\n",
    "                \"input_tokens\": metadata.get('prompt_eval_count', 0),\n",
    "                \"output_tokens\": metadata.get('eval_count', 0)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error durante la consulta RAG: {e}\")\n",
    "            return {\"answer\": \"Ocurri√≥ un error.\", \"sources\": [], \"input_tokens\": 0, \"output_tokens\": 0}\n",
    "\n",
    "# --- Aplicaci√≥n Streamlit ---\n",
    "\n",
    "@st.cache_resource\n",
    "def initialize_chatbot():\n",
    "    try:\n",
    "        config = EurekaConfig()\n",
    "        chatbot = EurekaChatbot(config)\n",
    "        chatbot.initialize_from_disk() # Carga desde el disco\n",
    "        return chatbot\n",
    "    except FileNotFoundError as e:\n",
    "        st.error(f\"üö® Error Cr√≠tico: {e}\")\n",
    "        return None\n",
    "\n",
    "# ... [Toda la UI de Streamlit de la versi√≥n anterior se mantiene igual] ...\n",
    "st.set_page_config(page_title=\"Eureka - ANLA\", page_icon=\"üåø\", layout=\"wide\")\n",
    "# ... Header, Sidebar, M√©tricas, Chat loop ...\n",
    "eureka_chatbot = initialize_chatbot()\n",
    "if not eureka_chatbot:\n",
    "    st.stop()\n",
    "# ... resto de la UI ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda 2: Instrucciones de Ejecuci√≥n\n",
    "\n",
    "1.  Aseg√∫rate de haber ejecutado `create_database.ipynb` y de que la carpeta `eureka_chroma_db` existe.\n",
    "2.  Abre una **terminal** en este directorio.\n",
    "3.  Ejecuta el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"Para iniciar, ejecuta en tu terminal: streamlit run app_chatbot.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}